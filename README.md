

# Spark développer pour le Big Data
<img src="https://github.com/rbizoi/Spark-developper-pour-le-Big-Data/blob/master/images/presentation.png" width="512">



## 01-L'écosystème Big Data Analytique

Une architecture de type Big Data Analytique doit permettre d'ingérer, consolider, traiter et analyser à grande vitesse en flux continu les données. Le traitement de flux doit être rapide, évolutif, tolérant aux pannes et de bout en bout, sans que l'utilisateur ait à se soucier du flux.<br>
<img src="https://github.com/rbizoi/Spark-developper-pour-le-Big-Data/blob/master/Chapitre-01/images/M01.06.png" width="512">

La structure de la machine virtuelle.<br>

<img src="https://github.com/rbizoi/Spark-developper-pour-le-Big-Data/blob/master/Chapitre-01/images/M01.07.png" width="512">
text-align: left;
<table>
<tr><th>1.     </th><th>Le déluge de données                             </th></tr>
<tr><th>2.     </th><th>Les systèmes de calcul distribué                 </th></tr>
<tr><th>3.     </th><th>Le système de fichiers distribué Hadoop (HDFS)   </th></tr>
<tr><th>4.     </th><th>Le système de traitements MapReduce              </th></tr>
<tr><th>5.     </th><th>Les extensions MapReduce                         </th></tr>
<tr><th>6.     </th><th>Le Big Data Analytique                           </th></tr>
<tr><th>6.1.   </th><th>La découverte                                    </th></tr>
<tr><th>6.2.   </th><th>La préparation des données                       </th></tr>
<tr><th>6.3.   </th><th>La conception du modèle                          </th></tr>
<tr><th>6.4.   </th><th>La construction du modèle                        </th></tr>
<tr><th>6.5.   </th><th>Les résultats                                    </th></tr>
<tr><th>6.6.   </th><th>La mise en production                            </th></tr>
<tr><th>7.     </th><th>L’analyse de données en flux continu             </th></tr>
<tr><th>8.     </th><th>L’installation                                   </th></tr>
<tr><th>9.     </th><th>Les produits nécessaires                         </th></tr>
<tr><th>10.    </th><th>Installer les prérequis                          </th></tr>
<tr><th>10.1.  </th><th>La configuration du système d'exploitation       </th></tr>
<tr><th>10.2.  </th><th>L'installation de l'environnement Java           </th></tr>
<tr><th>10.3.  </th><th>L'installation du langage Python                 </th></tr>
<tr><th>10.4.  </th><th>L'installation du langage R                      </th></tr>
<tr><th>10.5.  </th><th>La création des utilisateurs                     </th></tr>
<tr><th>10.6.  </th><th>La configuration automatique des prérequis       </th></tr>
<tr><th>11.    </th><th>Installer Apache Hadoop                          </th></tr>
<tr><th>12.    </th><th>Installer Apache Spark                           </th></tr>
<tr><th>12.1.  </th><th>L'installation des fichiers                      </th></tr>
<tr><th>12.2.  </th><th>La configuration de l'environnement              </th></tr>
<tr><th>12.3.  </th><th>Les environnements de commandes                  </th></tr>
<tr><th>12.3.1.</th><th>L'environnement de commande Scala                </th></tr>
<tr><th>12.3.2.</th><th>L'environnement de commande Python               </th></tr>
<tr><th>12.3.3.</th><th>L'environnement de commande R                    </th></tr>
<tr><th>12.4.  </th><th>L'installation et intégration avec Apache Hadoop </th></tr>
<tr><th>13.    </th><th>Installer Apache Hive                            </th></tr>
<tr><th>14.    </th><th>Installer Apache Zookeeper                       </th></tr>
<tr><th>15.    </th><th>Installer Apache Kafka                           </th></tr>
<tr><th>16.    </th><th>Installer Apache Zeppelin                        </th></tr>
<tr><th>17.    </th><th>Configurer le démarrage et l'arrêt du cluster    </th></tr>
<tr><th>17.1.  </th><th>Apache Hadoop                                    </th></tr>
<tr><th>17.2.  </th><th>Jupyter Notebook                                 </th></tr>
<tr><th>17.3.  </th><th>Apache Zeppelin                                  </th></tr>
</table>




## 02-L’architecture

## 03-La structure et les types de données

## 04-Les traitements et le flux de données

## 05-L’exploration, la préparation et la visualisation des données

## 06-Le « Machine Learning »

## 07-Le « Deep Learning »

## 08-La mise en production
